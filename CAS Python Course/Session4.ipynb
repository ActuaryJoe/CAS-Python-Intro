{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CAS 2020 Python Workshop: Session IV Pandas\n",
    "\n",
    "## Session Descriptions\n",
    "\n",
    "Welcome to CAS Python Workshop\n",
    "\n",
    "| No | Date       |Lead |   Contents  |\n",
    "|:---|:-----------|:----|:------------------------------------------------------------------|\n",
    "| 1  |  July 15   | BF  | Python programming basics variables, types, lists, dictionaries, functions, dates, strings, dir, help Simulated transactional data, computing Earned Premium (see 5)\n",
    "| 2  |  July 22   | SM  | Pandas 1: DataFrame creation and basic data manipulation; make a triangle, make development factors, make an exhibit from the CAS Loss Reserve Database\n",
    "| 3  |  July 29   | BF  | Pandas 2: data io with external sources: Excel, CSV, markdown, HTML, web; advanced data manipulation: querying, merging, indexes, stack, unstack, pivot-table, tidydata Prem and loss simulated dataâ€¦\n",
    "|**4**|**Aug 5**|**SM**| **Pandas 3: Visualization and Reporting plotting plus matplotlib, geopandas, jinja, COVID data, NY Auto data**\n",
    "| 5  |  Aug 12    | SM  | Simulation modeling, pandas, numpy, scipy.stats, Cat model, ELT, YLT, PML Points\n",
    "| 6  |  Aug 19    | BF  | Linear regression, lm, glm, sklearn Triangles analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Session IV Agenda: Visualization and Reporting\n",
    "\n",
    "Revised: **Pandas 3: Visualization and Reporting plotting plus matplotlib, jinja**\n",
    "\n",
    "**Meta-Goal: thought process and elicidating functionality**\n",
    "\n",
    "### Today's Modules\n",
    "\n",
    "* Jupyter and Friends: ecosystem \n",
    "* Recall from Session III: CAS Triangle Data and Triangles\n",
    "* Average Loss Ratio by Year by Line Exhibit \n",
    "* Simple plotting: Bar Chart, Line Plot, and Histogram \n",
    "* Make a Triangle and Develop \n",
    "* PPB - Poor Person's Bootstrap \n",
    "* Advanced graphics \n",
    "* Jinja templates and automating workflow\n",
    "* ...with some scattered regular expressions \n",
    "\n",
    "Google `geopandas` = mapping, GIS extension to Pandas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jupyter and Friends\n",
    "\n",
    "* **Jupyter** = **Ju**lia, **Pyt**hon and **R**\n",
    "* Project Jupyter is a nonprofit organization created to \"develop open-source software, open-standards, and services for interactive computing across dozens of programming languages.\"\n",
    "* **JupyterLab** is the next-generation user interface for Project Jupyter. It offers all the familiar building blocks of the classic Jupyter Notebook (notebook, terminal, text editor, file browser, rich outputs, etc.) in a flexible and powerful user interface. The first stable release was announced on February 20, 2018.\n",
    "* **Colaboratory** (also known as **Colab**) is a free Jupyter notebook environment that runs in the cloud and stores its notebooks on Google Drive\n",
    "* **IPython** (Interactive Python) is a command shell for interactive computing in multiple programming languages, originally developed for the Python programming language, that offers introspection, rich media, shell syntax, tab completion, and history\n",
    "\n",
    "*wikipedia.org*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Helpful Introspection Function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sdir(x, colwidth=80):\n",
    "    \"\"\"\n",
    "    Directory of useful elements, wrapped\n",
    "    \"\"\"\n",
    "    from textwrap import fill\n",
    "    l = [i for i in dir(x) if i[0] != '_']\n",
    "    mx = max(map(len, l))\n",
    "    mx += 2\n",
    "    fs = f'{{:<{mx:d}s}}'\n",
    "    l = [fs.format(i) for i in l if i[0] != '_']\n",
    "    print(fill('\\t'.join(l), colwidth))\n",
    "    \n",
    "sdir(int, 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in CAS Data\n",
    "\n",
    "Direct from URL!\n",
    "\n",
    "masterdata version contains trivial adjusments to Brian's dataset\n",
    "\n",
    "Call something else to avoid re-calling\n",
    "\n",
    "`df.head().T` often shows more useful information "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "url = 'http://www.mynl.com/RPM/masterdata.csv'\n",
    "df_triangle_0 = pd.read_csv(url)\n",
    "df_triangle_0.head().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Lag and Subset: Don't Cheat\n",
    "\n",
    "Work on a copy \n",
    "\n",
    "Virtues of zero based lag...\n",
    "\n",
    "`filter` to view a subset of columns \n",
    "\n",
    "`query` to subset rows, SQL like "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "df_triangle = df_triangle_0.copy()\n",
    "df_triangle['Lag'] -= 1\n",
    "df_triangle = df_triangle.query(' AY + Lag <= 1997 ')\n",
    "df_triangle.filter(regex='AY|Lag|GR|Loss').query('Lag == 9 and  UltIncLoss > 10 ').head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_triangle.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_triangle['Line'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in ['AY', 'DY', 'Lag', 'Line', 'GRName']:\n",
    "    u = df_triangle[c].unique()\n",
    "    print(f'{c} has {len(u)} unique values, {\"\" if len(u)<20 else \"starting\"}\\n {u[:20]}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 123456.789012\n",
    "print(f'{x}\\n{x:.3f}\\n{x:0,.1f}\\n{x:13.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarize and Plot\n",
    "\n",
    "Histograms, scatter plot and bar charts\n",
    "\n",
    "Avg loss ratio by line \n",
    "\n",
    "Largest companies by line\n",
    "\n",
    "Work with Lag == 9 (ultimate) observations to avoid double counting  \n",
    "\n",
    "Etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract subset \n",
    "bit = df_triangle.query('DY == 1997')[['GRName', 'Line', 'AY', 'UltIncLoss', 'EarnedPrem']]\n",
    "\n",
    "# add loss ratio \n",
    "bit['LR'] = bit.UltIncLoss / bit.EarnedPrem\n",
    "\n",
    "# sort values \n",
    "bit = bit.sort_values(['Line', 'EarnedPrem'], ascending=[True, False])\n",
    "\n",
    "# display \n",
    "bit.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize 1\n",
    "bit.groupby('Line')[['UltIncLoss', 'EarnedPrem']].sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "bit.groupby('Line')[['UltIncLoss', 'EarnedPrem']].sum().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kind= scatter, hist, bar, barh, line, etc.\n",
    "bit.groupby('Line')[['UltIncLoss', 'EarnedPrem']].sum().plot(kind='barh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exhibit and Graph Showing Loss Ratio by Line and Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bit.groupby(['AY', 'Line'])[['UltIncLoss', 'EarnedPrem']].sum().head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = bit.groupby(['AY', 'Line'])\n",
    "i = 0\n",
    "for n, b in g:\n",
    "    print(n)\n",
    "    display(b.head())\n",
    "    i += 1\n",
    "    if i > 3:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bit.groupby(['AY', 'Line']).sum().head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bit.groupby(['AY', 'Line']).agg({'UltIncLoss': np.sum, \n",
    "                                   'EarnedPrem': np.sum, 'LR': np.mean }).head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bit.groupby(['AY', 'Line']).apply(lambda x : x.UltIncLoss.sum() / x.EarnedPrem.sum()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = bit.groupby(['AY', 'Line']).apply(lambda x : x.UltIncLoss.sum() / x.EarnedPrem.sum()).unstack(1)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add all-lines total \n",
    "b['All Lines'] = bit.groupby('AY').apply(lambda x : x.UltIncLoss.sum() / x.EarnedPrem.sum()) \n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdir(ticker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plots with a few frills \n",
    "ax = b.plot(lw=1, figsize=(8,6))\n",
    "ax.xaxis.set_major_locator(ticker.FixedLocator(range(1988, 1998)))\n",
    "ax.yaxis.set_major_formatter(ticker.StrMethodFormatter('{x:.0%}'))\n",
    "ax.grid(lw=.25)\n",
    "ax.set(ylabel='Loss Ratio', \n",
    "       xlabel='Accident Year', \n",
    "       title='Med Mal Bucks Improving\\nIndustry Loss Ratio Trend',\n",
    "       )\n",
    "ax.lines[-1].set(lw=3, c='C0')\n",
    "ax.lines[1].set(lw=2)\n",
    "# call legend last to reflect all your changes\n",
    "ax.legend(ncol=2, fontsize=8, title='Line of Business');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stylin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.style.format('{:0.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.style.format('{:,.3f}').\\\n",
    "    background_gradient(subset=['All Lines'], cmap='viridis_r').\\\n",
    "    bar(vmin=0.5, vmax=1.2, subset=['Med Mal']).\\\n",
    "    set_caption('An Over-Produced DataFrame')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subset to a Company or Group of Companies \n",
    "\n",
    "Subset to a single company...how do we find it? \n",
    "\n",
    "Regular expressions \n",
    "\n",
    "`.str` Method \n",
    "\n",
    "World of string methods \n",
    "\n",
    "Find `contains` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdir(df_triangle.GRName.str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?df_triangle.GRName.str.contains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bit = df_triangle.loc[df_triangle.GRName.str.contains('state', regex=True)]\n",
    "bit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bit.GRName.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdir(re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bit2 = df_triangle.loc[df_triangle.GRName.str.contains('state', flags=re.IGNORECASE, regex=True)]\n",
    "bit2.GRName.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regular expressions are great...\n",
    "# all names starting Am or ending Inc or containting ee or ... \n",
    "bit2 = df_triangle.loc[df_triangle.GRName.str.contains('^Am|Inc$|[e]{2}', flags=re.IGNORECASE, regex=True)]\n",
    "bit2.GRName.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pull Out a Single Company\n",
    "\n",
    "There are six lines, let's try to find a co that writes all six\n",
    "\n",
    "Check you get a single company "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lines by company \n",
    "lbc = df_triangle.groupby(\"GRName\").apply(lambda x : len(x.Line.unique()) ).sort_values(ascending=False)\n",
    "lbc[lbc>=5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick your favorite\n",
    "co = 'West Bend Mut Ins Grp' \n",
    "co"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_triangle.loc[df_triangle.GRName.str.contains(co)]\n",
    "df.GRName.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Line.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subset and Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finally just pull in the three columns of interest\n",
    "co = 'West Bend Mut Ins Grp' \n",
    "df = df_triangle.loc[df_triangle.GRName.str.contains(co)]\n",
    "df = df[['GRName', 'Line', 'AY', 'Lag', 'PaidLoss', 'CaseIncLoss', 'UltIncLoss', 'EarnedPrem']]\n",
    "df = df.set_index(['GRName', 'Line', 'AY', 'Lag'])\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Reshape into Triangle\n",
    "\n",
    "The joys of `NaN`'s\n",
    "\n",
    "Display of data vs. form of data \n",
    "\n",
    "```\n",
    "There should be one-- and preferably only one --obvious way to do it.\n",
    "```\n",
    "\n",
    "...doesn't really hold for libraries!\n",
    "\n",
    "use `stack` and `unstack` vs. `pivot` or `pivot_table`.\n",
    "\n",
    "Triangles are just awkward, whether you convert to a column or not. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['PaidLoss']].unstack(3).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Lagged Loss by Group \n",
    "\n",
    "Use `groupby` and `shift`\n",
    "\n",
    "Easier than the `apply` approach (I came up with) last week "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lagged loss \n",
    "df.iloc[:, :2].groupby(level=[0,1,2]).shift(-1).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# link ratios \n",
    "df.iloc[:, :2].groupby(level=[0,1,2]).shift(-1).head(10) / df.iloc[:, :2].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BTW, of course\n",
    "(\n",
    "    df.iloc[:, :2].groupby(level=[0,1,2]).shift(-1).head(10) / df.iloc[:, :2].head(10)\n",
    ").reset_index(drop=True).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Link Ratios for Both Lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[f'{i}LDF' for i in ['Paid', 'Inc']]] = df.iloc[:, :2].groupby(level=[0,1,2]).shift(-1) / df.iloc[:, :2]\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paid LDF triangle \n",
    "df.iloc[:, -2].unstack(3).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop 1997 and development 9\n",
    "# second drop must come after pivot\n",
    "df.iloc[:, -2].drop(1997, level=2).unstack(3).drop(9, axis=1).head(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trg = df.iloc[:, -2].drop(1997, level=2).unstack(3).drop(9, axis=1).head(9)\n",
    "trg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PPB: Poor Person's Bootstrap\n",
    "\n",
    "Simulate a link ratio from each development lag and take the product to generate a range and distribution of possible FTUs for the most recent accident year. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample(trg, bins=50):\n",
    "    \"\"\"\n",
    "    make distribution of FTUs by resampling link ratio by development lag\n",
    "    input df with lag columns and rows AYs\n",
    "    \"\"\"\n",
    "    # initialize \n",
    "    kpp = np.array([1.0])\n",
    "    \n",
    "    # np.kron computes the outer product of two arrays: all sensible products \n",
    "    for i in range(0, trg.shape[1]):\n",
    "        kpp = np.kron(kpp, trg.iloc[:trg.shape[0]-i, i])\n",
    "\n",
    "    ult = pd.Series( kpp )\n",
    "    return ult    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = resample(trg)\n",
    "u.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fact = lambda x : x == 0 or x * fact(x-1)\n",
    "fact(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.getrecursionlimit())\n",
    "sys.setrecursionlimit(3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fact(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intermission: Coding Golf\n",
    "\n",
    "Challenge: Create bar chart showing frequency of digits in 1000 factorial.\n",
    "\n",
    "Use as few lines of code as possible. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coding Golf: \n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "fact = lambda x : x == 0 or x * fact(x-1)\n",
    "\n",
    "pd.DataFrame( {'digit': np.arange(0,10), 'f': [str(fact(1000)).count(i) for i in '0123456789']} ). \\\n",
    "    set_index('digit'). \\\n",
    "    plot(kind='bar', rot=0, legend=None). \\\n",
    "    set(title='Frequency of Digits in 1000!');\n",
    "\n",
    "# Python: Par 3 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Back to PPB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9! = 362880 as expected \n",
    "u.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u.hist(bins=50, ec='white');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u.sort_values().reset_index(drop=True).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bit = df[['PaidLDF', 'IncLDF']].drop(1997, level=2, axis=0).drop(9, level=3, axis=0).unstack(3)\n",
    "bit.head(18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply PPB to each line of business"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bit.columns.levels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b2 = bit.groupby(level=[0,1]).apply(\n",
    "#    lambda x : pd.DataFrame({'Paid' : resample(x['PaidLDF']), 'Incurred': resample(x['IncLDF'])}))\n",
    "\n",
    "b2 = bit.groupby(level=[0,1]).apply(lambda x : pd.DataFrame(\n",
    "        { i : resample(x[i]) for i in x.columns.levels[0]}))\n",
    "\n",
    "print(b2.shape, 5*fact(9))\n",
    "b2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b3 = b2.unstack(1)\n",
    "b3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss12 = df.query(' Lag == 0 and AY == 1997 ')[['PaidLoss', 'CaseIncLoss']].unstack(1).droplevel(2, axis=0)\n",
    "loss12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexes: You Don't Always Get What You Want\n",
    "\n",
    "```\n",
    "You can't always get what you want, \n",
    "but if you try sometimes, \n",
    "you might find, \n",
    "you get what you need.\n",
    "\n",
    "Mick Jagger\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b3.head() * loss12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wait, whaaat? Product will matches index and then take product.\n",
    "\n",
    "No overlapping index values! \n",
    "\n",
    "Need product ignoring index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b4 = b3 * loss12.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b4.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b4d = b4.describe()\n",
    "b4d.loc['CV'] = b4d.loc['std'] / b4d.loc['mean']\n",
    "b4d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axs = plt.subplots(3, 2, figsize=(8, 9), constrained_layout=True)\n",
    "axi = iter(axs.flat)\n",
    "\n",
    "for l in b4.columns.levels[1]:\n",
    "    ax = next(axi)\n",
    "    m = sd = 0\n",
    "    for a, pi in zip([1,.5], b4.columns.levels[0]):\n",
    "        m0, sd0 = b4d.loc[['mean', 'std'], (pi, l)]\n",
    "        m = max(m, m0)\n",
    "        sd = max(sd, sd0)\n",
    "        bins = b4[(pi, l)].\\\n",
    "            hist(lw=0.5,ec='white', density=True, bins=25, ax=ax, label=pi, alpha=a)\n",
    "    ax.set(title=l, xlim=[m-4*sd, m+4*sd])\n",
    "    if l == b4.columns.levels[1][0]:\n",
    "        ax.legend(loc='upper right')\n",
    "\n",
    "# add a figure title and drop the last plot\n",
    "f.suptitle(b3.index[0][0])\n",
    "f.axes[-1].remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjust the x axis on the Work Comp plot\n",
    "f.axes[4].set(xlim=((25000, 50000)))\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set all axes the same \n",
    "for ax in f.axes[:-1]:\n",
    "    ax.set(xlim=[-1000,51000])\n",
    "# tweak legend\n",
    "f.axes[0].legend(loc='upper left')\n",
    "f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## So, What's the Answer for WC?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%who "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# strings just concatenate; no problem with line breaks within ( ) \n",
    "p12 = df_triangle_0.query(' Line == \"Work Comp\" and '\n",
    "                    'GRName == @co and AY==1997 and Lag == 9 ' )['UltIncLoss']\n",
    "p12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.axes[4].axvline(p12.iloc[0], c='k', lw=2, label='Actual Ult')\n",
    "f.axes[4].set(xlim=[25000, 50000])\n",
    "f.axes[4].legend()\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bit.xs('Work Comp', level=1).stack(0).swaplevel(1,2).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save figure\n",
    "f.savefig('filename.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jinja Templates and Automating Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jinja2\n",
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdir(jinja2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?jinja2.Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = jinja2.Template('''\n",
    "\n",
    "# {{company}} Link Ratios \n",
    "\n",
    "## {{line}}\n",
    "\n",
    "{{ table }}\n",
    "\n",
    "{{commentary}}\n",
    "\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%who"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trg.droplevel((0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = trg.droplevel((0,1)).fillna(0).to_markdown(floatfmt='.3f').replace(\"0.000\", '')\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md = t.render(company=\"West Bend\", line=\"Commercial Auto\", table=table, commentary=\"Paid LDFs.\")\n",
    "print(md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(md))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recap\n",
    "\n",
    "1. Jupyter and Friends\n",
    "2. Summarize and Plot\n",
    "3. Styles\n",
    "4. Discover and `.str`\n",
    "5. Subset and Index\n",
    "6. Reshape and Triangles\n",
    "7. Lags and Links\n",
    "8. PPB\n",
    "9. Golf\n",
    "10. `apply`\n",
    "11. Advanced plotting example\n",
    "12. Jinja templates and automating workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework\n",
    "\n",
    "Try weighted average of LDFs or last 3 or last 5.\n",
    "\n",
    "Make an exhibit showing EP, IL, FTU, Ult, Actual Ultimate, Error by method.\n",
    "\n",
    "Which is the best method across all cos and lines? \n",
    "\n",
    "Play with the original data. Extract largest n cos by line, fastest growing, lowest loss ratio, lowest loss ratio with premium > a reasonable threshold, etc., \n",
    "\n",
    "Make exhibits presentation ready.\n",
    "\n",
    "Export to Excel.\n",
    "\n",
    "Remember: `sdir(object)` to see what it will do! Use the online help `?function`.\n",
    "\n",
    "[Pandas documentation](https://pandas.pydata.org/pandas-docs/stable/index.html)\n",
    "\n",
    "[Matplotlib documentation](https://matplotlib.org/)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
